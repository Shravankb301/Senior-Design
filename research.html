<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Research</title>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css">

  <style>
     body{
      background-color: #000042 ;
      color: #fff;
    }
      ol li {
        float:left;
        padding: 10px;
        text-align: left;
        font-family: Times;
        font-size: 14px;
        font-style: normal;
        font-weight: normal;
        text-decoration: none;
        text-transform: none;
     }
     p{
      text-align: left;
      font-family: Times;
      font-size: 14px;
      font-style: normal;
      font-weight: normal;
      text-decoration: none;
      text-transform: none;
   
     }
  </style>
</head>
<body>
  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <div class="container-fluid">
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse justify-content-end" id="navbarNav">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link "  href="home.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link "  href="team.html">Meet The Team</a>
          </li>
          <li class="nav-item">
            <a class="nav-link active"  aria-current="page"  href="research.html">Research</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="testing.html">Testing</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="analysis.html">Analysis</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>
  </nav>



  <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

    <div class="container">
      <div class="container py-5">
        <h3 class="text-center mb-5">Summary of Relevant Research</h3>

        <p>Research has led us to believe that GitHub and Copilot can be incredibly useful in the hands of both experienced and inexperienced programmers. These autocomplete tools can aid in checking, correcting, and understanding how to use complex functions.  A lot of the uncovered shows that the use of autocomplete tools has mostly been for texts, and search results. However, as time goes on, more interest has been put on the fact that autocomplete tools can be used for programming, especially with OpenAI and GitHub Copilot. Copilot has an advantage due to it being open source, when using Copilot, it uses the various projects, repositories, and code on GitHub. However, this can also lead to problems with human error if someone fixes something wrong. The fact that it is open source allows updates to the repositories and projects to be much faster than if a company had to update it itself.
          Recent advancements in natural language processing have led to near-human performance in multiple natural language tasks. We demonstrate that a fine-tuned machine learning model can perform well in code generation tasks. [2][8][10][2] </p>
    
        <p>Autocompletion is a common workspace feature that is used to recommend code snippets as developers type in their IDEs. Although several non-negligible effect sizes of autocompletion targets are detected between software engineers and other developers, the rates at which these targets appear do not vary to a significant degree. Most modern Integrated Development Environments (IDEs) provide autocompletion features, which allow developers to complete code fragments by selecting from a list of recommended options that appear as they type. Autocomplete may also save developers' time by decreasing the amount of keyboard input that is required to reference identifiers. The median auto-completion rates of software engineers and other developers are not statistically different. Software engineers tend to use local variables and parameters as autocompletion targets, while other developers use methods and types. However, none of these results are statistically significant. We measure how often developers use autocomplete features by computing the number of autocomplete events in each session and normalizing the raw count by the total number of events in that session. To improve autocompletion tools, it would be useful to know who is using them. Moreover, it would reveal which types of users need better support. Results show that autocompletion rates are similar for software engineers and other developers, and the difference in data dispersion is minimal. Software engineers do not use autocomplete features differently from other developers, but four of the six studied autocompletion target types have non-negligible effect sizes. They state that “the median rate for other developers (0.846%) is slightly higher than that of software engineers (0.703%);” when it comes to autocomplete usage. Although this is negligible in statistical standards, this is still showing that when autocomplete tools are implemented, they are utilized by everyone in the programming sphere. [4] </p>

        <p>When looking into tools, there have been some discoveries that a lot of programmers have trouble with completing their tasks efficiently and within time. That's what Jacob Jackson aims to do with Deep Tab Nine, a code autocompletion tool. Jackson, a computer science undergraduate student at the University of Waterloo, in Canada, and a previous intern at AI research company OpenAI, first launched Tab Nine as a code completion plug-in in November 2018, and then added deep-learning capabilities to create what's now known as Deep Tab Nine. Deep Tab Nine uses GPT-2—a natural-language-processing model designed by OpenAI—to generate relevant coding suggestions and predict the elements in each line of code. Deep Tab Nine works with existing code editors and integrated-development environments (IDEs) and currently supports 22 programming languages, including C++, CSS, HTML, Java, JavaScript, PHP, Python, and SQL. So, to get the completion suggestion, you run this model many times and ask it what token it thinks will come next, and then you run it again (on actual code) and that's when you get the (list of suggested) tokens.[11][21] </p>
 
        <p>Autocomplete isn’t just used for just code and text, RapMOD, an auto-completion approach integrated into modeling tools. Upon each editing operation a user performs, the approach reactively recommends Auto-completions comparable to that in IDEs. Supported modeling activities are expressed as complex event patterns and processed by an inference engine. We found that our approach reduced the overall time for performing complex modeling scenarios by 27 percent. To this we can have an addition to reducing the difficulty of coding, researchers have explained that there is a significant difference in speed compared to programming without autocomplete tools. In an article called “Programmers Can Code Faster with This AI-Based Auto completer Tool” by Manisha Priyadarshini it states that “Deep Tab Nine is a new auto-completion tool that suggests finished lines of codes based on what you have written so far. It is a deep learning-based tool that works for multiple programming languages.” which is designed and proven to “help developers code faster.” because “is a deep learning-based tool that was trained on two million files from GitHub. It predicts each token based on the tokens that come before it.” With many IDEs implementing their own versions of this tool, this could allow programmers to finish their projects much faster than before. Deep Tab Nine is a new auto-completion tool that suggests finished lines of codes based on what you have written. It is a deep learning-based tool that works for multiple programming languages. Based on a predictive text deep-learning language model GPT-2 by Open AI, Deep Tab Nine aims to help developers code faster. Code Autocompletion with Deep Learning Deep Tab Nine is a deep learning-based tool that was trained on two million files from GitHub. It predicts each token based on the tokens that come before it. [9][18] </p>
   
        <p>Researchers are attempting to improve the way that autocomplete works in IDEs and code transfer learning in order to make autocomplete much more efficient. When using code transfer has been used to assist autocomplete it has been shown to improve accuracy precision by about 12.8%. Eclipse IDE allows for use in deep learning models and code mining. Which has been leading to the use of AI in things unexpected like electronic devices in cities. One of the important objectives of smart cities is to provide electronic services to citizens, however, this requires the building of related software which is a time-consuming process. Integrated Development Environments (IDEs) are well-known tools that have brought together the features of various tools within one package. To this end, the Eclipse Theia (cloud-based IDE) and its AI-based extensions are explored as a case study. The findings show that recommender system models, language modeling, deep learning models, code mining, and attention mechanisms are used frequently to facilitate programming. Furthermore, some research has used NLP techniques and AI-based virtual assistance to promote the interaction between developers and projects. Our studies investigated how transfer learning might enhance autocompletion. Previous research demonstrated that the most accurate autocompletion models are produced with a training corpus made up of real-world samples gathered from programmers' IDE usage. However, there could only be a few real-world autocompletion tests- please available in the preferred programming language for some tool developers. This work demonstrated how the strength of transfer learning permits pretraining on example code sequences written in different languages, without the use of an IDE, and without autocompletion before fine-tuning on the autocompletion prediction task. Our findings demonstrate that by beginning with a pretrained model, they can achieve equivalent accuracy while significantly reducing the number of fine-tuning samples. These results from the offline examination were verified in online A/B tests that were carried out on thousands of Facebook software developers. [8][25] </p>
  
        <p>The GPT-3 API is only accessible via invitation, and the cost has not yet been established. Additionally, even OpenAI itself is unsure about the precise application of the technology. The API could be utilized to enhance chatbot functionality, provide fresh gaming environments, and much more. OpenAI was initially going to be private with the AI tools that they were using but according to an article by James Vincent, they went public with the AI tools despite fears of malicious use of GPT-2, the text tools that were used initially before moving onto GPT-3. The idea around these tools was to allow freedom to make anything that the users would like, from chess programs to autocomplete tools. [15] </p>
    
        <p>Developers define elements in ways which reflect patterns, and HTML documents exhibit patterns which reflect their structure. Autocomplete suggestions can help developers make edits consistent with the existing structure and be informed when they write documents inconsistent with this structure. Machine learning systems can identify patterns from data, but traditional systems lack explain ability and editability, making it impossible for users to correct or edit learned patterns. To help developers understand code patterns and explain code completions, we presented code patterns as a Table OF If/then rules. Each rule describes a set of conditions in which it applies and the resulting predicted target. When inspecting code patterns, developers may identify patterns that are correct or incorrect, and may wish to create new code patterns expressing their intent. Standard code patterns are machine learned and may be changed or removed at any time. Developers can create their own code patterns by clicking the Add button and specifying the target and conditions. [3][7] </p>
 
        <p>Previous research demonstrated that the most accurate autocompletion models are produced with a training corpus made up of real-world samples gathered from programmers' IDE usage. It investigated how transfer learning might enhance autocompletion. However, there could only be a few real-world autocompletion tests- please available in the preferred programming language for some tool developers. This work demonstrated how the strength of transfer learning permits pretraining on example code sequences written in different languages, without the use of an IDE, and without autocompletion before fine-tuning on the autocompletion prediction task. The findings demonstrate that by beginning with a pretrained model, we should achieve equivalent accuracy while significantly reducing the number of fine-tuning samples. These results from the offline examination were verified in online A/B tests that were carried out on thousands of Facebook software developers. [24] </p>
      
        <p>“In software development, autocomplete code can be an essential tool to accelerate coding. However, many of these tools built into the IDEs are limited to suggesting only methods or arguments, often presenting to the user long lists of irrelevant items. Since innovations introduced by transformer-based models that have reached the state-of-the-art performance in tasks involving natural language processing (NLP), the application of these models also in tasks involving code intelligence, such as code completion, has become a frequent object of study in recent years.” [14] </p>
  
        <p>Autocompletion is a searching feature that offers suggestions for search terms as a user. An analysis of search logs from a library federated searching tool reveals common errors in how search queries are entered. More than half (51 %) of all searches appear to be for known items. As a plug-in has become ubiquitous on-site searches large and small. Examples include Real Time Query Expansion (RTQE), interactive query expansion, Search-as-you-Type (SayT), query completion, auto-suggest, and suggestive searching/search suggestions. We can examine possible algorithms to use in building this type of tolerance into search systems. White and Marchionni assess best practices for implementation of search-term-suggestion systems. Autocomplete can lead users down incorrect search paths, researchers warn. Providing suggestions at this initial stage also led to better-quality initial queries. University of Illinois at Urbana-Champaign conducted two rounds of usability testing on a version of its website with autocomplete built in. Students use autocomplete to correct spelling on known-item searches, speed up the search process, focus broad searches, augment search-term vocabulary. Autocomplete is helpful "if you have an idea of a word but not how it's spelled," one student said. Spelling correction was the one universally acknowledged use of autocomplete for subject-based searching. Autocomplete is a viable tool to incorporate site-wide into library search interfaces. Students expect suggestions to produce usable results within a library's collections. There is an ongoing need to investigate possible search-term dictionaries. Autocomplete can be used to help users understand how a varied vocabulary is important for achieving relevant results in a research setting. Traditional reference practice emphasizes a prescriptive path for research that involves analyzing which aspects of a topic or alternate vocabulary will be most relevant to a search before search-term entry. [1] </p>

        <p>“GitHub and OpenAI have launched a technical preview of a new AI tool called Copilot, which lives inside the Visual Studio Code editor and autocompletes code snippets. Copilot does more than just parrot back code it's seen before, according to GitHub. It instead analyzes the code you've already written and generates new matching code, including specific functions that were previously called. Examples on the project`s website include automatically writing the code to import tweets, draw a scatterplot, or grab a Goodreads rating” [12] </p>

        <p>We can show the usage of these tools can allow programmers of lesser expertise to perform on a higher level. While this will not replace actual programming jobs in the Computer Science industry, it will absolutely create a shift in the amount of expertise required for a programming job. In the video “Who will Survive the AI Revolution” youtuber thug notes states that “Deep learning is incredibly effective, so much so that researchers don't fully understand how machines using deep learning come to their conclusions. This is because after a certain point, computers running deep learning systems start to program themselves.”  because of this, “there is an intense focus on creating human-like AI that can replace people in the workforce. In this way, it drives down wages for many of us, even as it amplifies the market power of a few who are lucky enough to own that tech.” [23] With the way that technology has impacted blue collar jobs, it is more than likely that office jobs like programming will be impacted by either shifting to using AI tools and or jobs that are more like maintaining the AI used to program. </p>
  
        <p>The use of AI tools like OpenAI’s Codex has been considered in the field of cybersecurity. They used AI tools to find and fix common vulnerabilities and bugs in cybersecurity. Hammond Pierce in the article Examining Zero-Shot Vulnerability Repair with Large Language Models, they state that “Developers perform many tasks in creating and maintaining software; they can sometimes fall into patterns of insecure code, such as those in MITRE’s Common Weakness Enumeration (CWE) database.” and that “Tools that can speed up or even eliminate this costly manual bug fixing process stand to greatly improve the state of software security. (“Examining Zero-Shot Vulnerability Repair with Large Language Models - arXiv”) In this work, we want to use LLMs to repair identified security bugs by generating alternative replacements.” In the article they used GPT-2, which was at the time OpenAI’s model for codex, to repair buggy programs that were given to the natural language processors, and it resulted in the discovery that “the (Codex) LLMs can repair vulnerable programs (RQ1) when given a suitable repair prompt. CWE-787 scenario saw 491 suggested patches that fix the bug (2.2% of suggestions)” meaning that there is potential for using AI tools, even in the cybersecurity department of computer science. [16] </p>
     
        <p>Natural Language and AI Tools have also been used in chemistry. There have been breakthroughs and developments with Chen’s natural language processing, called Codex. An article by the name of “Natural language processing models that automate programming will transform chemistry research and teaching” explains that “These off-the-shelf tools can enable students to perform tasks in minutes which might have taken a large portion of their PhD to complete just ten years ago.” however a lot of research is spent with “repetitive coding tasks has been replaced by learning the interfaces to these numerous software packages;” With these natural language processors, this could not only effect programming, but also other fields of science that require a bit of programming, either for graphing or displaying data. Glen M. Hocky and Andrew D. White explain that “These new NLP models are able to eliminate intermediate steps and allow researchers to get on with their most important task” and “Codex removes the tedium of programming and lets chemists focus the high-level science enabled with programs. Furthermore, the process of creating a prompt string, mentally checking whether it seems reasonable, testing that code on a sample input, and then iterating by breaking down the prompt string into simpler tasks will result in better algorithmic thinking by chemists.” [25] </p>
     
        <p>In an unexpected way, coding and the world of creativity have collided due to natural language processing. With the rise of AI tools like GPT-3, there has been a rise of worries when it comes to the creativity of code, as Ermira Murati explains in “Language & Coding Creativity”, they state “This does not put human designers out of a job. Rather, they gain a team of assistants to take on their most rote tasks, allowing them instead to focus on curating and improving on good ideas or developing their own.” [6] Because of the way that GPT-3 and other Natural Language Processors work, the jobs of programmers will change, but programmers will not be removed outright. Instead prioritizing on the other sides of programming. This would result in programmers focusing on either fixing issue from the AI’s errors, designing the prompts for the AI, or finding ways to combine different coding segments from different prompts. </p>
     
        <p>To see how effective OpenAI’s Codex and Copilot's coding is, Nhan Nguyen and Sarah Nadi did a study involving how effective and correct Copilot's answers to different coding questions was. According to “An Empirical Evaluation of GitHub Copilot’s Code Suggestions” they used “33 Leet Code questions with varying difficulty levels (4 easy, 17 medium, and 12 hard).” Then use Copilot to give suggestions on how to solve the questions. They found that “in 23/33 questions” that “Copilot produces an accepted solution for at least one language. Per language, 14 (42%), 19 (57%), 9 (27%), and 13 (39%) of Copilot solutions for Python, Java, JavaScript, and C respectively are accepted”, another interesting discovery is that “We find that Copilot solutions rarely exceeded Leet Code's time limit and that compilation errors occur only in 8/33 (24%) of the C solutions, but in none of the Java solutions. Note that Python and JavaScript are not compiled languages so their code will naturally not result in any compilation error. Except for JavaScript solutions (33%), runtime errors are also not that frequent.” [19] The correctness of the questions is heavily influenced by the language used, with Java being the most effective and JavaScript being the least effective. </p>
      
        <p>The use of Natural Language Processors by programmers has its pros and cons. There are advantages to the fact that Codex makes it easier to understand new languages for newer programmers. As Ekaterina, Vladmir, and Igor explained, “Codex may make it easier to work with new codebases or new languages as for novice programmers, as well as for already skilled software developers” however there are problems such as time and over-reliance, as the article explains “Copilot can provide code snippets that work effectively, which can lead to developers’ over-reliance on this technology. Or the results, where the code looks correct to the user, pass accuracy checking, but in fact does something undesirable or even harmful” [5] With this information in mind, the use of natural language processing is incredibly useful as a tool. However, overreliance on this tool would provide issues with compliance with the answers that Codex and Copilot, even if they prove to be incorrect. </p>
     
        <p>An interesting use for artificial intelligence like ChatGPT and Copilot has been found in the robotics industry. In an article called “ChatGPT for Robotics: Design Principles and Model Abilities” made by Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor of Microsofts’ Autonomous Systems and Robotics Research, they “aim to demonstrate the potential of ChatGPT for robotics applications.” by using it in the “creation of a high-level function library”. While researching ChatGPT they uncovered that “ChatGPT is capable of solving various robotics-related tasks in a zero-shot fashion, while adapting to multiple form factors, and allowing for closed-loop reasoning through conversation.” After giving the tool instructions and creating a function library. They discovered that it was able to “solve several robotics tasks in a zero-shot fashion” and complete a series of simulations with ease. Thanks to the use of ChatGPT, they had created “PromptCraft, a collaborative open-source platform for researchers to share examples of prompting strategies and test their algorithms in sample robotic environments.” [26] </p>
      
        <p>With ChatGPT being incredibly unique in the way that it can be used for more than just programming. A few people have wondered how well the AI program could do with advanced mathematics. The article “Mathematical Capabilities of ChatGPT”, they decided to “focus on performing a detailed analysis of the mathematical capabilities of ChatGPT.” by giving the AI “a collection of multiple datasets of prompts, totaling 728 prompts, for which ChatGPT’s output was manually rated by experts.” The study used a point value from 5 to 1 to determine how well ChatGPT worked on the problems. In the end, they had found out that while ChatGPT has strong capabilities in the realm of coding, it often had problems something called “Olympiad-Problem-Solving" this is usually where problem solving and complex puzzles, and chess are implemented into complex mathematical situations. In this section “No rating of 5 was awarded, and only two ratings of 4 were achieved” and in the end “ChatGPT performed poorly” in this problem set. In the end after testing, they concluded that “ChatGPT is not yet ready to deliver high-quality proofs or calculations consistently.” and “It seems fair to say that ChatGPT is inconsistently bad at advanced mathematics” [27] </p>
    
        <p>Another way ChatGPT was tested outside of coding was in the field of law, as the AI chatbot could be used to not only help with writing legal documents, but also possibly writing and answering law school exams. In the article “ChatGPT Goes to Law School”, Jonathan Choi, Kristin Hickman, Amy Monahan, and Daniel Schwarcz had given the program “Over 95 multiple choice questions and 12 essay questions” that were from “four real exams at the University of Minnesota Law School”. These questions ranged from “Constitutional Law” to “Taxation, and Torts”. In the end, “ChatGPT passed all four classes based on its final exam, averaging a C+”, which is a barely passing score at the Minnesota Law School and “would earn credit toward the JD but place the student on academic probation” After analyzing the answers given by ChatGPT, they found that “ChatGPT performed better on the essay components of the exams than on the multiple choice.” with the performance resulting in the chatbot being in “the 17th percentile;”, they also found that of the average performance on multiple choice resulted in being placed in “the 7th percentile.” The researchers concluded that “We expect that ChatGPT could substantially improve the performance of students on exams.” especially “low-performing students and those who suffer under time constraints.” This is because instead of leaving an answer blank, one could “ask ChatGPT to compose a quick answer” [28] or even using it to improve answers that students do not feel confident in. </p>
  
        <p>With more research being done day by day on ChatGPT, one thing that seems to be a common problem is its low performance with logic puzzles, such as chess. Issues arise as a strange phenomenon referred to as Artificial Hallucinations plague ChatGPT’s responses, causing chaos when it comes to logical situations. In the article “Artificial Hallucinations in ChatGPT: Implications in Scientific Writing” they express concerns that “Although large language models such as ChatGPT can produce increasingly realistic text” The problems that arise from “artificial hallucinations.” make the “the accuracy and integrity of using these models in scientific writing are unknown.” They investigate the reason behind artificial hallucinations by “asking it to provide short paragraphs on specific medical and non-medical topics and evaluating the generated text.” After having the ChatGPT model write an article about “the mechanism of homocysteine-induced osteoporosis.” they had found out that “the first two facts provided by ChatGPT are correct” but had nothing to do with the prompt given. When they asked ChatGPT about the sources it used for its paragraph, “None of the provided paper titles existed” and in an even stranger twist when searching for these papers using PubMed ID’s (also known as PMIDs) they “the resulting paper is entirely different and in a different field”. [29] With this in mind, it is possible for ChatGPT to get confused and produce random fake information.  </p>

        <p>Another way that they tested ChatGPT in the field of medicine was through using exams about life support. The article from Resuscitation titled “Can ChatGPT pass the life support exams without entering the American heart association course?” M. John Douma, A. Al Sayed, K. Suleman et al tested the chatbot by giving it “life support exams (AHA BLS Exams A and B from February 2016, 25 questions each; and AHA ACLS Exams A and B from March 2016, 50 questions each).” as ChatGPT does not “provide information beyond 2021” They made it clear that “The threshold for passing each exam is 84%.” In the end ChatGPT obtained “achieved 68% (17/25) and 64% (16/25) accuracy in the 25-question AHA BLS exams and 68.4% (26/38) and 76.3% (29/38) accuracy in the two 38-question AHA ACLS exams.” One interesting detail they pointed out was that “For 21.5% (25/116) of answers ChatGPT provided the reference.” and the most common sources were “The AHA and American College of Cardiology (84%; 21/25)”. Unfortunately, despite being “on average very relevant, accurate and showed significantly better congruence with resuscitation guidelines than previous study.” ChatGPT couldn’t “reach the passing threshold for any of the exams.” [30] </p>
        
        <p>A possible use for the Artificial Intelligence chatbot is possibly translating text from one language to another. ChatGPT has been shown to translate different types of texts to another language, but in the article “Cross-Lingual Summarization via ChatGPT”, researchers Jiaan Wang, Yunlong Liang, Fandong Meng, Zhixu Li, Jianfeng Qu, and Jie Zhou wonder if they can possibly push the limits by having the chatbot perform “cross-lingual summarization (CLS)” which is the act of obtaining a “target-language (e.g., German) summary” from “a lengthy document in a different source language (e.g., English)”. In order to do this, they would “design various prompts to guide ChatGPT to perform CLS from different paradigms” In their studies, they found out that “Without the interactive prompt, we find that ChatGPT (e2e) typically performs worse than the pipelines” primarily because this is “still challenging for a single model to directly perform CLS” which involves “both the translation and summarization ability, making the model struggle to simultaneously perform them.” however when presented with an interactive prompt, ChatGPT ends up having “more concise summaries can be generated after inputting the interactive prompt, e.g., 183.7 tokens generated by Chat- GPT (e2e) on CrossSum, while the counterpart of ChatGPT (e2e+interact) is 66.4 tokens.” [31] </p>
        
        

      

     </div>

     <div class="container py-5">
      <h3 class="text-center mb-5">Work Cited</h3>

      <ol type="1">
        <li>“Autocomplete as research tool: A study on providing search suggestions.” [Online]. Available: https://www.researchgate.net/publication/284583661_Autocomplete_as_Research_Tool_A_Study_on_Providing_Search_Suggestions. [Accessed: 27-Oct-2022].  </li>
        
        <li>“Automatic code generation using pre-trained language models.” [Online]. Available: http://cs230.stanford.edu/projects_spring_2020/reports/38907662.pdf. [Accessed: 27-Oct-2022].  </li>
        
        <li>“Cybersecurity,” IEEE Xplore. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/1201257. [Accessed: 27-Oct-2022]. </li>
        
        <li>“Do software engineers use autocompletion features differently than other developers,” IEEE Xplore. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/8595186. [Accessed: 27-Oct-2022].  </li>
   
        <li>E. A. Moroz, V. O. Grizkevich, and I. M. Novozhilov, “The Potential of Artificial Intelligence as a Method of Software Developer's Productivity Improvement,” IEEE Xplore, 2017. [Online]. Available: https://ieeexplore.ieee.org/document/9755659. [Accessed: 03-Dec-2022].    </li>
     
        <li>E. Murati, “Language & coding creativity,” MIT Press, 01-May-2022. [Online]. Available: https://direct.mit.edu/daed/article/151/2/156/110626/Language-amp-Coding-Creativity. [Accessed: 03-Dec-2022].   </li>
      
        <li>“Editable AI: Mixed human-ai authoring of code patterns,” IEEE Xplore. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/8818871?casa_token=hb2dcVoymXwAAAAA%3AlYQ8v6HQsRCtE13YjMKhD5Lloy5azm9npQT1X8ropZsCJHJlWk2Kz3xydUJcSw-_Qi8Az72liYA. [Accessed: 27-Oct-2022].  </li>
        
        <li>“Improving code autocompletion with transfer learning,” IEEE Xplore. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/9793983. [Accessed: 27-Oct-2022].  </li>
       
        <li>“OpenAI’s latest breakthrough is astonishingly powerful, but still ...” [Online]. Available: https://fully-human.org/wp-content/uploads/2020/10/Vincent_OpenAI-latest-breakthrough-is-astonishingly-powerful-but-still-fighting-its-flaws.pdf. [Accessed: 27-Oct-2022].  </li>
      
        <li>“Reactive auto-completion of modeling activities,” IEEE Xplore. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/8745532?casa_token=TL23dW2B4EYAAAAA%3AdwExnBKjpWk5yoPQtLK1bBfOTcZNvAQdmKHiPFFt7VIYXGnw-ydwC6c7oVxWozjJbIaDLfrKgRCW. [Accessed: 27-Oct-2022]. </li>
       
        <li>“Visual studio code extension and auto-completion for Mizar language,” IEEE Xplore. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/9644021?casa_token=yc9fMr4tP4cAAAAA%3A8X-5hOBGg3gYhJ05j0APO5XRKAmk2bA67osmfCtn7I8dWe8ybrH3AuPdy3By1mIwjA5herhM3Zlz. [Accessed: 27-Oct-2022]. </li>
       
        <li>D. Gershgorn, “GitHub and OpenAI launch a new AI tool that generates its own code,” The Verge, 29-Jun-2021. [Online]. Available: https://www.theverge.com/2021/6/29/22555777/github-openai-ai-tool-autocomplete-code. [Accessed: 27-Oct-2022]. </li>
       
        <li>G. M.  Hocky and A. D. White, “Natural language processing models that automate programming will transform chemistry research and teaching,” Digital Discovery, 03-Feb-2022. [Online]. Available: https://pubs.rsc.org/en/content/articlehtml/2022/dd/d1dd00009h. [Accessed: 03-Dec-2022]. </li>
  
        <li>G. T. Meyrer, D. A. Araújo, and S. J. Rigo, “Code autocomplete using Transformers,” SpringerLink, 01-Jan-1970. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-030-91699-2_15. [Accessed: 27-Oct-2022]. </li>
    
        <li>H. Pearce, B. Tan, B. Ahmad, R. Karri, and B. Dolan-Gavitt, “Examining Zero-shot vulnerability repair with large language models,” arXiv.org, 15-Aug-2022. [Online]. Available: https://arxiv.org/abs/2112.02125. [Accessed: 03-Dec-2022]. </li>
        
        <li>J. Vincent, “OpenAI will start selling its next-generation tech, and the first customers include Reddit,” The Verge, 11-Jun-2020. [Online]. Available: https://www.theverge.com/2020/6/11/21287966/openai-commercial-product-text-generation-gpt-3-api-customers. [Accessed: 27-Oct-2022]. </li>
        
        <li>James Finnie-Ansley the University of Auckland, J. Finnie-Ansley, T. U. of Auckland, Paul Denny the University of Auckland, P. Denny, Brett A. Becker University College Dublin, B. A. Becker, U. C. Dublin, Andrew Luxton-Reilly the University of Auckland, A. Luxton-Reilly, “The robots are coming: Exploring the implications of OpenAI Codex on Introductory Programming: Australasian Computing Education Conference,” ACM Other conferences, 01-Feb-2022. [Online]. Available: https://dl.acm.org/doi/10.1145/3511861.3511863. [Accessed: 27-Oct-2022].  </li>
        
        <li>K. Roose, “We need to talk about how good A.I. is getting,” The New York Times, 24-Aug-2022. [Online]. Available: https://www.nytimes.com/2022/08/24/technology/ai-technology-progress.html. [Accessed: 27-Oct-2022].  </li>
    
        <li>M. Priyadarshini, “Programmers can code faster with this AI-based Autocompleter Tool,” Foss bytes, 29-Jul-2019. [Online]. Available: https://fossbytes.com/programmers-can-code-faster-with-this-ai-based-autocompleter-tool/. [Accessed: 27-Oct-2022]. </li>

        <li>N. Nguyen and S. Nadi, “An empirical evaluation of GitHub copilot's code suggestions,” ACM Digital Library, May-2022. [Online]. Available: https://github.com/nhtnhan/MSR2022_Copilot. [Accessed: 03-Dec-2022]. </li>
  
        <li>R. D. Caballar, “Q&A: This autocompletion tool aims to supercharge your coding,” IEEE Spectrum, 18-Aug-2022. [Online]. Available: https://spectrum.ieee.org/qa-this-autocompletion-tool-aims-to-supercharge-your-coding. [Accessed: 27-Oct-2022]. </li>

        <li>S. G. Lilt, S. Green, Lilt, L. V. Profile, J. H. U. of Washington, J. Heer, U. of Washington, U. of W. V. Profile, C. D. M. S. University, C. D. Manning, S. University, S. U. V. Profile, A. for C. Machinery, Contributor Metrics Expand All Spence Green Stanford University Publication Years2010 - 2021Publication cou, and Spence Green Stanford University Publication Years2010 - 2021Publication counts11Available for Download10Citation count130Downloads (cumulative)29, “Natural language translation at the intersection of AI and HCI,” Communications of the ACM, 01-Sep-2015. [Online]. Available: https://dl.acm.org/doi/fullHtml/10.1145/2767151?casa_token=ZXRi5g2uhdYAAAAA%3AEsyAr__mt2c9koE5fzZfkGv54X4N0dlyvKh67x0hNx5VISfC5YrGHlMMu2s5lRkYAvVGZP2jK8TK7Q. [Accessed: 27-Oct-2022]. </li>
      
        <li> thugnotes, “Who will survive the AI revolution?” YouTube, 29-Aug-2022. [Online]. Available: https://www.youtube.com/watch?v=gv0aI9p0t4k. [Accessed: 27-Oct-2022].  </li>
       
        <li>W. Zhou, S. Kim, V. Murali, and G. A. Aye, “Improving code autocompletion with transfer learning,” arXiv.org, 12-May-2021. [Online]. Available: https://arxiv.org/abs/2105.05991v1. [Accessed: 27-Oct-2022].  </li>
      
        <li>Z. Alizadehsani, E. G. Gomez, H. Ghaemi, S. R. González, J. Jordan, A. Fernández, and B. Pérez-Lancho, “Modern Integrated Development Environment (IDES),” SpringerLink, 01-Jan-1970. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-030-78901-5_24. [Accessed: 27-Oct-2022]. </li>
  
        <li>S. Vemprala, R. Bonatti, A. Bucker, and A. Kapoor, “Chatgpt for robotics,” Microsoft Research, 03-Mar-2023. [Online]. Available: https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/. [Accessed: 03-Mar-2023].   </li>

        <li>S. Frieder, L. Pinchetti, R.-R. Griffiths, T. Salvatori, T. Lukasiewicz, P. C. Petersen, A. Chevalier, and J. Berner, “Mathematical capabilities of chatgpt,” arXiv.org, 31-Jan-2023. [Online]. Available: https://arxiv.org/abs/2301.13867. [Accessed: 05-Mar-2023]. </li>
      
        <li>J. H. Choi, K. E. Hickman, A. Monahan, and D. Schwarcz, “Chatgpt goes to law school,” SSRN, 25-Jan-2023. [Online]. Available: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4335905. [Accessed: 06-Mar-2023]. </li>
        
        <li>H. Alkaissi and S. I. McFarlane, “Artificial hallucinations in CHATGPT: Implications in scientific writing,” Cureus, 19-Feb-2023. [Online]. Available: https://assets.cureus.com/uploads/editorial/pdf/138667/20230219-28928-6kcyip.pdf. [Accessed: 07-Mar-2023]. </li>
  
        <li>N. Fijačko, L. Gosak, G. Štiglic, C. T. Picard, and M. J. Douma, “Can chatgpt pass the life support exams without entering the American Heart Association Course?,” Resuscitation, 10-Feb-2023. [Online]. Available: https://www.resuscitationjournal.com/article/S0300-9572(23)00045-X/fulltext. [Accessed: 09-Mar-2023].   </li>
        
        <li>J. Wang, Y. Liang, F. Meng, Z. Li, J. Qu, and J. Zhou, “Cross-lingual summarization via CHATGPT,” arXiv.org, 28-Feb-2023. [Online]. Available: https://arxiv.org/abs/2302.14229. [Accessed: 08-Mar-2023].</li>
      </ol>
   </div>



     <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    </div>


  



</body>
</html>